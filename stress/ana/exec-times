#!/usr/bin/env python3

import argparse
import re

from collections import OrderedDict

import pandas as pd


LOG_REGEX = re.compile(r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:\.\d{3})?:\s+')

START_REGEX = re.compile(
    r'Using (?P<cores>\d+) cores on (?P<host>.+)'
    ' to process (?P<events>\d+) events of (?P<file>.+) \[\d+/\d+\]'
)

BENCHMARK_REGEX = re.compile(
    r'(?P<label>\w+)\s+(?P<events>\d+) events\s+'
    'total time =\s+(?P<total_time>\d+\.\d+) s\s+'
    'average event time =\s+(?P<avg_time>\d+\.\d+) ms'
)

ORCH_AVG_TIME_REGEX = re.compile(
    r'Average processing time  =\s+(?P<avg_time>\d+\.\d+) ms'
)


results_list = []
results_frame = pd.DataFrame()


def nonblank_lines(f):
    for line in f.readlines():
        line = LOG_REGEX.sub('', line.strip())
        if line:
            yield line


def parse_time(log_file):
    with open(log_file) as f:
        benchmark_trial = False
        benchmark_block = False
        for line in nonblank_lines(f):
            if not benchmark_trial:
                match = START_REGEX.match(line)
                if match:
                    data = OrderedDict()
                    data['Cores'] = int(match.group('cores'))
                    benchmark_trial = True

            if benchmark_trial and not benchmark_block:
                if line.startswith('Benchmark results:'):
                    benchmark_block = True
                    continue

            if benchmark_block:
                match = BENCHMARK_REGEX.match(line)
                if match:
                    label = match.group('label')
                    data[label] = float(match.group('avg_time'))
                    continue
                match = ORCH_AVG_TIME_REGEX.match(line)
                if match:
                    data['Orchestrator'] = float(match.group('avg_time'))
                    results_list.append(data)
                benchmark_trial = False
                benchmark_block = False

    global results_frame
    results_frame = pd.DataFrame(results_list)
    results_frame = results_frame.groupby('Cores').mean().round(decimals=2)


def write_results(print_csv=True):
    csv_data = results_frame.to_csv(float_format='%.2f')
    csv_data = csv_data.strip()
    if print_csv:
        print(csv_data)


if __name__ == '__main__':

    argparser = argparse.ArgumentParser()
    argparser.add_argument('log_file', help='the multicore-test output')
    args = argparser.parse_args()

    parse_time(args.log_file)
    write_results(print_csv=True)
