#!/usr/bin/env python3

import argparse
import re
import os
import yaml

from datetime import datetime
from string import Template
from collections import OrderedDict

import nbformat as nbf
import pandas as pd


LOG_REGEX = re.compile(r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:\.\d{3})?:\s+')

START_REGEX = re.compile(
    r'Using (?P<cores>\d+) cores on (?P<host>.+)'
    ' to process (?P<events>\d+) events of (?P<file>.+) \[\d+/\d+\]'
)

BENCHMARK_REGEX = re.compile(
    r'(?P<label>\w+)\s+(?P<events>\d+) events\s+'
    'total time =\s+(?P<total_time>\d+\.\d+) s\s+'
    'average event time =\s+(?P<avg_time>\d+\.\d+) ms'
)

ORCH_AVG_TIME_REGEX = re.compile(
    r'Average processing time  =\s+(?P<avg_time>\d+\.\d+) ms'
)


results_list = []
results_frame = pd.DataFrame()


def nonblank_lines(f):
    for line in f.readlines():
        line = LOG_REGEX.sub('', line.strip())
        if line:
            yield line


def parse_time(log_file):
    with open(log_file) as f:
        benchmark_trial = False
        benchmark_block = False
        for line in nonblank_lines(f):
            if not benchmark_trial:
                match = START_REGEX.match(line)
                if match:
                    data = OrderedDict()
                    data['Cores'] = int(match.group('cores'))
                    benchmark_trial = True

            if benchmark_trial and not benchmark_block:
                if line.startswith('Benchmark results:'):
                    benchmark_block = True
                    continue

            if benchmark_block:
                match = BENCHMARK_REGEX.match(line)
                if match:
                    label = match.group('label')
                    data[label] = float(match.group('avg_time'))
                    continue
                match = ORCH_AVG_TIME_REGEX.match(line)
                if match:
                    data['Orchestrator'] = float(match.group('avg_time'))
                    results_list.append(data)
                benchmark_trial = False
                benchmark_block = False

    global results_frame
    results_frame = pd.DataFrame(results_list)
    results_frame = results_frame.groupby('Cores').mean().round(decimals=2)


def write_results(print_csv=True, nb_file=None):
    csv_data = results_frame.to_csv(float_format='%.2f')
    csv_data = csv_data.strip()
    if print_csv:
        print(csv_data)

    def calc_xlim():
        return results_frame.reset_index()['Cores'].max() + 2

    def calc_time_lim():
        t_max = results_frame['TOTAL'].max()
        return int((t_max + 70) / 100 + 1) * 100

    if nb_file:
        nb = nbf.v4.new_notebook()

        data = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'services': results_frame.columns[1:-3].tolist(),
            'csv_data': csv_data,
            'xlim': calc_xlim(),
            'time_lim': calc_time_lim(),
        }
        new_cell = {
            'code': nbf.v4.new_code_cell,
            'markdown': nbf.v4.new_markdown_cell,
        }

        dir_path = os.path.dirname(os.path.realpath(__file__))
        template_path = os.path.join(dir_path, 'multicore-nb.yml')
        with open(template_path) as f:
            template = yaml.load(f)
            for cell in template['notebook']['cells']:
                content = Template(cell['content']).substitute(data).strip()
                nb_cell = new_cell[cell['type']](content)
                nb.setdefault('cells', []).append(nb_cell)

        with open(nb_file, 'w') as f:
            nbf.write(nb, f)


if __name__ == '__main__':

    argparser = argparse.ArgumentParser()
    argparser.add_argument('--nb-file', dest='nb_file', action='store',
                           help='create a Jupyter notebook')
    argparser.add_argument('log_file', help='the multicore-test output')
    args = argparser.parse_args()

    parse_time(args.log_file)
    write_results(print_csv=True, nb_file=args.nb_file)
